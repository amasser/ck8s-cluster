global:
  rbac:
    pspEnabled: {{ requiredEnv "ENABLE_PSP" }}

alertmanager:
  enabled: {{ requiredEnv "ENABLE_CUSTOMER_ALERTMANAGER" }}

grafana:
  enabled: false

# TODO: These do not work out of the box with RKE
# If we switch to kubeadm they should be fine, otherwise we should look into
# how to configure them properly for RKE.
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false

prometheusOperator:
  createCustomResource: false

kube-state-metrics:
  podSecurityPolicy:
    enabled: {{ requiredEnv "ENABLE_PSP" }}

kubeApiServer:
  serviceMonitor:
    metricRelabelings:
      - action: keep
        sourceLabels: [__name__]
        regex: '(apiserver_request_count|apiserver_request_latencies_bucket|apiserver_client_certificate_expiration_seconds_count|apiserver_request_duration_seconds_sum|apiserver_request_duration_seconds_count|APIServiceRegistrationController_depth)'

prometheus:
  ingress:
    enabled: true
    annotations:
      # type of authentication
      nginx.ingress.kubernetes.io/auth-type: basic
      # name of the secret that contains the user/password definitions
      nginx.ingress.kubernetes.io/auth-secret: prometheus-auth
      # message to display with an appropriate context why the authentication is required
      nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
      certmanager.k8s.io/issuer: letsencrypt-{{ requiredEnv "CERT_TYPE" }}
      {{ if (env "PROMETHEUS_WC_WHITELIST_SOURCE_RANGE") }}
      nginx.ingress.kubernetes.io/whitelist-source-range: {{ env "PROMETHEUS_WC_WHITELIST_SOURCE_RANGE" }}
      {{ end }}
    labels: {}
    hosts:
    - prometheus.{{ requiredEnv "ECK_BASE_DOMAIN"}}
    paths:
    - /
    tls:
    - secretName: prometheus-general-tls
      hosts:
      - prometheus.{{ requiredEnv "ECK_BASE_DOMAIN"}}

  prometheusSpec:
    externalLabels:
      cluster: workload_cluster

    # Dont add prometheus labels.
    prometheusExternalLabelNameClear: true
    replicaExternalLabelNameClear: true

    # Empty selector to select all namespaces
    serviceMonitorNamespaceSelector:
      matchLabels: {}
    # Select all service monitors
    serviceMonitorSelector:
      matchLabels: {}
    podMonitorNamespaceSelector:
      matchLabels: {}
    podMonitorSelector:
      matchLabels: {}
    ruleNamespaceSelector:
      matchLabels: {}
    ruleSelector:
      matchLabels: {}

    {{ if eq (env "ENABLE_CUSTOMER_ALERTMANAGER") "true"  }}
    # Connect to separately managed alertmanager
    alertingEndpoints:
      - name: alertmanager-operated
        namespace: monitoring
        port: web
        pathPrefix: /
    {{ end }}
    resources:
      requests:
        memory: 1Gi # Total will be 50Mi more, acounting for prometheus-config-reloader & prometheus-rulefiles
        cpu: "300m" # Total will be 200m more, acounting for prometheus-config-reloader & prometheus-rulefiles
      limits:
        memory: 2Gi # Total will be 50Mi more, acounting for prometheus-config-reloader & prometheus-rulefiles
        cpu: 1 # Total will be 200m more, acounting for prometheus-config-reloader & prometheus-rulefiles

    ## How long to retain metrics
    ##
    retention: {{ requiredEnv "PROMETHEUS_RETENTION_WC" }}

    ## Maximum size of metrics
    ##
    retentionSize: {{ requiredEnv "PROMETHEUS_RETENTION_SIZE_WC" }}

    ## Prometheus StorageSpec for persistent data
    ## ref: https://github.com/coreos/prometheus-operator/blob/release-0.29/Documentation/user-guides/storage.md
    ##
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: {{ requiredEnv "STORAGE_CLASS" }}
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: {{ requiredEnv "PROMETHEUS_STORAGE_SIZE_WC" }}
        selector: {}

    {{ if eq (env "STORAGE_CLASS") "nfs-client"  }}
    additionalScrapeConfigs:
    - job_name: 'node-exporter'
      scrape_interval: 30s
      metrics_path: /metrics
      scheme: http
      static_configs:
      - targets:
        - '{{ requiredEnv "NFS_WC_SERVER_IP" }}:9100'
    {{ end }}

    {{ if eq (env "ENABLE_POSTGRESQL") "true"  }}
    additionalScrapeConfigs:
    - job_name: 'postgresql_metrics'
      scrape_interval: 30s
      metrics_path: /metrics
      static_configs:
      - targets:
        - 'postgres.tempus.elastisys.se:9187'

    - job_name: 'postgresql_node_metrics'
      scrape_interval: 30s
      metrics_path: /metrics
      scheme: http
      static_configs:
      - targets:
        - 'postgres.tempus.elastisys.se:9100'
    {{ end }}
